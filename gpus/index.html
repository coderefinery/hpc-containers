<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Running containers that use GPUs &mdash; Container on HPC with Apptainer  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
      <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx_lesson.css" />
      <link rel="stylesheet" type="text/css" href="../_static/term_role_formatting.css" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx_rtd_theme_ext_color_contrast.css" />
      <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />

  
    <link rel="shortcut icon" href="../_static/coderefinery.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/minipres.js"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script src="../_static/tabs.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex/" />
    <link rel="search" title="Search" href="../search/" />
    <link rel="next" title="Sharing reproducible containers" href="../sharing/" />
    <link rel="prev" title="MPI programs and containers" href="../mpi/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../" class="icon icon-home">
            Container on HPC with Apptainer
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">The lesson</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intro_and_motivation/">Intro to containers (on HPC)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics_running_containers/">Basics of running containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../container_images/">Intro to container images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../building_images/">Building Apptainer images</a></li>
<li class="toctree-l1"><a class="reference internal" href="../binding_folders/">Binding folders into your container</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mpi/">MPI programs and containers</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Running containers that use GPUs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#using-nvidia-s-gpus">Using NVIDIA’s GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-amd-s-gpus">Using AMD’s GPUs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#example-container-model-training-with-accelerate">Example container: Model training with accelerate</a></li>
<li class="toctree-l2"><a class="reference internal" href="#review-of-this-session">Review of this session</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../sharing/">Sharing reproducible containers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extras</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../services_apps/">Services and apps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tips_tricks/">Tips, tricks and frequently asked questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Exercises</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../verify_installation/">Verify Apptainer Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../first_build/">Building Your First Container</a></li>
<li class="toctree-l1"><a class="reference internal" href="../python_exercise/">Python environment in a container</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../">Container on HPC with Apptainer</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Running containers that use GPUs</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/coderefinery/ttt4hpc_containers/blob/main/content/gpus.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="running-containers-that-use-gpus">
<h1>Running containers that use GPUs<a class="headerlink" href="#running-containers-that-use-gpus" title="Permalink to this heading"></a></h1>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Learn how you can use GPUs with containers</p></li>
</ul>
</div>
<p>If your program uses GPUs, you’ll need to make the GPUs visible in
the container. This is done by giving additional flag to the
apptainer command.</p>
<p>The container itself must have the correct GPU computing libraries
installed inside the image (CUDA toolkit for NVIDIA and ROCm for AMD).
Code inside the image needs to be installed with GPU support as well.
Apptainer will only mount the driver libraries and the GPU devices
that these toolkits need to run the code on GPUs.</p>
<section id="using-nvidia-s-gpus">
<h2>Using NVIDIA’s GPUs<a class="headerlink" href="#using-nvidia-s-gpus" title="Permalink to this heading"></a></h2>
<p>When using NVIDIA’s GPUs that use the CUDA-framework the flag is <code class="docutils literal notranslate"><span class="pre">--nv</span></code>.</p>
<p>As an example, let’s get a CUDA-enabled PyTorch-image:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>apptainer<span class="w"> </span>pull<span class="w"> </span>pytorch-cuda.sif<span class="w"> </span>docker://docker.io/pytorch/pytorch:2.2.2-cuda12.1-cudnn8-runtime
</pre></div>
</div>
<p>Now when we launch the image, we can give the image GPU access with</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>apptainer<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>pytorch-cuda.sif<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import torch; print(torch.cuda.is_available())&#39;</span>
</pre></div>
</div>
<figure class="align-default" id="id1">
<img alt="../_images/nv_example.png" src="../_images/nv_example.png" />
<figcaption>
<p><span class="caption-text">Figure 1: Enabling NVIDIA’s GPUs in containers</span><a class="headerlink" href="#id1" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<div class="dropdown admonition">
<p class="admonition-title">Expected result</p>
<p>If you run this in a system with an NVIDIA GPU, you should see the following result:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>apptainer<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>pytorch-cuda.sif<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import torch; print(torch.cuda.is_available())&#39;</span>
<span class="go">True</span>
</pre></div>
</div>
</div>
</section>
<section id="using-amd-s-gpus">
<h2>Using AMD’s GPUs<a class="headerlink" href="#using-amd-s-gpus" title="Permalink to this heading"></a></h2>
<p>When using AMD’s GPUs that use the ROCm-framework the flag is <code class="docutils literal notranslate"><span class="pre">--rocm</span></code>.</p>
<p>As an example, let’s get a ROCm-enabled PyTorch-image:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>apptainer<span class="w"> </span>pull<span class="w"> </span>pytorch-rocm.sif<span class="w"> </span>docker://docker.io/rocm/pytorch:rocm6.1_ubuntu22.04_py3.10_pytorch_2.1.2
</pre></div>
</div>
<p>Now when we launch the image, we can give the image GPU access with</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>apptainer<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--rocm<span class="w"> </span>pytorch-rocm.sif<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import torch; print(torch.cuda.is_available())&#39;</span>
</pre></div>
</div>
<figure class="align-default" id="id2">
<img alt="../_images/rocm_example.png" src="../_images/rocm_example.png" />
<figcaption>
<p><span class="caption-text">Figure 2: Enabling AMD’s GPUs in containers</span><a class="headerlink" href="#id2" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<div class="dropdown admonition">
<p class="admonition-title">Expected result</p>
<p>If you run this in a system with an AMD GPU, you should see the following result:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>apptainer<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--rocm<span class="w"> </span>pytorch-rocm.sif<span class="w"> </span>python<span class="w"> </span>-c<span class="w"> </span><span class="s1">&#39;import torch; print(torch.cuda.is_available())&#39;</span>
<span class="go">True</span>
</pre></div>
</div>
</div>
</section>
<section id="example-container-model-training-with-accelerate">
<h2>Example container: Model training with accelerate<a class="headerlink" href="#example-container-model-training-with-accelerate" title="Permalink to this heading"></a></h2>
<p><a class="reference external" href="https://huggingface.co/docs/accelerate/en/index">Accelerate</a>
is a library designed for running distributed PyTorch code.</p>
<p>Let’s create a container that can run a simple training example
that can utilizes multiple GPUs.</p>
<p>Container starts from an existing container with PyTorch installed
and installs a few missing Python packages:</p>
<p><a class="reference download internal" download="" href="../_downloads/07ab827005bb2435cfa6959d87adca94/accelerate_cuda.def"><code class="xref download docutils literal notranslate"><span class="pre">accelerate_cuda.def</span></code></a>:</p>
<div class="highlight-singularity notranslate"><div class="highlight"><pre><span></span><span class="k">Bootstrap</span>:<span class="w"> </span>docker
<span class="k">From</span>:<span class="w"> </span>pytorch/pytorch:<span class="m">2.2.2</span>-cuda12<span class="m">.1</span>-cudnn8-runtime

<span class="gh">%post</span>

<span class="w">  </span>pip<span class="w"> </span>install<span class="w"> </span>accelerate<span class="w"> </span>evaluate<span class="w"> </span>datasets<span class="w"> </span>scipy<span class="w"> </span>scikit-learn<span class="w"> </span>transformers
</pre></div>
</div>
<p>Submission script that launches the container looks like this:</p>
<p><a class="reference download internal" download="" href="../_downloads/af972a158f9b94f597741a2187c63f9c/run_accelerate_cuda.sh"><code class="xref download docutils literal notranslate"><span class="pre">run_accelerate_cuda.sh</span></code></a>:</p>
<div class="highlight-slurm notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="kp">#SBATCH --mem=32G</span>
<span class="kp">#SBATCH --nodes=1</span>
<span class="kp">#SBATCH --ntasks-per-node=1</span>
<span class="kp">#SBATCH --gpus-per-task=2</span>
<span class="kp">#SBATCH --cpus-per-task=12</span>
<span class="kp">#SBATCH --time=00:10:00</span>
<span class="kp">#SBATCH --output=accelerate_cuda.out</span>

<span class="nb">export</span><span class="w"> </span><span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="k">$((</span><span class="w"> </span><span class="nv">$SLURM_CPUS_PER_TASK</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nv">$SLURM_GPUS_ON_NODE</span><span class="w"> </span><span class="k">))</span>

apptainer<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>--nv<span class="w"> </span>accelerate_cuda.sif<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>torchrun<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--nproc_per_node<span class="w"> </span><span class="nv">$SLURM_GPUS_ON_NODE</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>./nlp_example.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--mixed_precision<span class="w"> </span>fp16
</pre></div>
</div>
<div class="sphinx-tabs docutils container">
<div aria-label="Tabbed content" class="closeable" role="tablist"><button aria-controls="panel-0-0-0" aria-selected="true" class="sphinx-tabs-tab" id="tab-0-0-0" name="0-0" role="tab" tabindex="0">Triton (Aalto)</button></div><div aria-labelledby="tab-0-0-0" class="sphinx-tabs-panel" id="panel-0-0-0" name="0-0" role="tabpanel" tabindex="0"><p>To build the image:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>srun<span class="w"> </span>--mem<span class="o">=</span>32G<span class="w"> </span>--cpus-per-task<span class="o">=</span><span class="m">4</span><span class="w"> </span>--time<span class="o">=</span><span class="m">01</span>:00:00<span class="w"> </span>apptainer<span class="w"> </span>build<span class="w"> </span>accelerate_cuda.sif<span class="w"> </span>accelerate_cuda.def
</pre></div>
</div>
<p>To run the example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">$ </span>wget<span class="w"> </span>https://raw.githubusercontent.com/huggingface/accelerate/refs/heads/main/examples/nlp_example.py
<span class="gp">$ </span>sbatch<span class="w"> </span>run_accelerate_cuda.sh
<span class="gp">$ </span>cat<span class="w"> </span>accelerate_cuda.out
<span class="go">Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: [&#39;classifier.bias&#39;, &#39;classifier.weight&#39;]</span>
<span class="go">You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.</span>
<span class="go">You&#39;re using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.</span>
<span class="go">epoch 0: {&#39;accuracy&#39;: 0.7598039215686274, &#39;f1&#39;: 0.8032128514056225}</span>
<span class="go">epoch 1: {&#39;accuracy&#39;: 0.8480392156862745, &#39;f1&#39;: 0.8931034482758621}</span>
<span class="go">epoch 2: {&#39;accuracy&#39;: 0.8406862745098039, &#39;f1&#39;: 0.888507718696398}</span>
</pre></div>
</div>
</div></div>
</section>
<section id="review-of-this-session">
<h2>Review of this session<a class="headerlink" href="#review-of-this-session" title="Permalink to this heading"></a></h2>
<div class="admonition-key-points-to-remember admonition">
<p class="admonition-title">Key points to remember</p>
<ul class="simple">
<li><p>Code inside the container image needs to support GPU calculations.</p></li>
<li><p>Container image should have a working CUDA / ROCm toolkit installed.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">--nv</span></code> / <code class="docutils literal notranslate"><span class="pre">--rocm</span></code>-flag to mount the device drivers inside of the image.</p></li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../mpi/" class="btn btn-neutral float-left" title="MPI programs and containers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../sharing/" class="btn btn-neutral float-right" title="Sharing reproducible containers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024-, The contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>